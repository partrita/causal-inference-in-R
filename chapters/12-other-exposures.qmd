# 연속형 및 범주형 노출

## 연속형 노출 {#sec-continuous-exposures}

{{< include 00-setup.qmd >}}

```{r}
#| echo: false
# TODO: 첫 번째 판이 완료되면 제거
status("wip")
```

### 연속형 노출에 대한 성향 점수 계산하기

성향 점수는 연속형 노출을 포함하여 다른 많은 유형의 노출로 일반화됩니다.
본질적으로 워크플로는 동일합니다. 즉, 노출이 결과인 모델을 적합시킨 다음 해당 모델을 사용하여 두 번째 결과 모델에 가중치를 부여합니다.
연속형 노출의 경우 선형 회귀는 성향을 만드는 가장 간단한 방법입니다.
확률 대신 누적 밀도 함수를 사용합니다.
그런 다음 이 밀도를 사용하여 결과 모델에 가중치를 부여합니다.

예를 살펴보겠습니다.
`touringplans` 데이터셋에는 놀이기구의 게시된 대기 시간에 대한 정보가 있습니다.
또한 관찰된 실제 시간에 대한 제한된 양의 데이터도 있습니다.
고려할 질문은 다음과 같습니다. 오전 8시 일곱 난쟁이 광산 열차의 게시된 대기 시간이 오전 9시 실제 대기 시간에 영향을 미치는가?
다음은 DAG입니다.

```{r}
#| label: fig-dag-avg-wait
#| code-fold: true
#| message: false
#| warning: false
#| fig.cap: >
#|    특정 공원의 아침 게시 대기 시간과 오후 5시에서 6시 사이의 평균 대기 시간 간의 관계에 대해 제안된 DAG.

library(tidyverse)
library(ggdag)
library(ggokabeito)

coord_dag <- list(
  x = c(Season = -1, close = -1, weather = -2, extra = 0, x = 1, y = 2),
  y = c(Season = -1, close = 1, weather = 0, extra = 0, x = 0, y = 0)
)

labels <- c(
  extra = "엑스트라 매직 모닝",
  x = "평균 게시 대기 시간",
  y = "평균 실제 대기 시간",
  Season = "티켓 시즌",
  weather = "과거 최고 기온",
  close = "공원 폐장 시간"
)

dagify(
  y ~ x + close + Season + weather + extra,
  x ~ weather + close + Season + extra,
  extra ~ weather + close + Season,
  coords = coord_dag,
  labels = labels,
  exposure = "x",
  outcome = "y"
) |>
  tidy_dagitty() |>
  node_status() |>
  ggplot(
    aes(x, y, xend = xend, yend = yend, color = status)
  ) +
  geom_dag_edges_arc(curvature = c(rep(0, 7), .2, 0, .2, .2, 0), edge_colour = "grey70") +
  geom_dag_point() +
  geom_dag_label_repel(seed = 1602) +
  scale_color_okabe_ito(na.value = "grey90") +
  theme_dag() +
  theme(
    legend.position = "none",
    axis.text.x = element_text()
  ) +
  coord_cartesian(clip = "off") +
  scale_x_continuous(
    limits = c(-2.25, 2.25),
    breaks = c(-2, -1, 0, 1, 2),
    labels = c(
      "\n(1년 전)",
      "\n(6개월 전)",
      "\n(3개월 전)",
      "오전 8시-9시\n(오늘)",
      "오전 9시-10시\n(오늘)"
    )
  )
```

@fig-dag-avg-wait에서 주요 교란 변수는 공원이 문을 닫는 시간, 과거 최고 기온, 놀이기구에 엑스트라 매직 모닝 시간이 있는지 여부 및 티켓 시즌이라고 가정합니다.
이것은 DAG의 유일한 최소 조정 집합이기도 합니다.
교란 변수는 노출과 결과보다 먼저 발생하며 (정의에 따라) 노출은 결과보다 먼저 발생합니다.
평균 게시 대기 시간은 공원에서 예상과 다른 시간을 게시할 수 있으므로 이론적으로 조작 가능한 노출입니다.


모델은 이진 노출 사례와 유사하지만 게시된 시간이 연속 변수이므로 선형 회귀를 사용해야 합니다.
확률을 사용하지 않으므로 정규 밀도에서 가중치에 대한 분모를 계산합니다.
그런 다음 `exposure`에 대해 `.fitted`를 평균으로, `mean(.sigma)`를 표준 편차로 사용하여 `dnorm()` 함수를 사용하여 분모를 계산합니다.

```{r}
#| eval: false
lm(
  exposure ~ confounder_1 + confounder_2,
  data = df
) |>
  augment(data = df) |>
  mutate(
    denominator = dnorm(exposure, .fitted, mean(.sigma, na.rm = TRUE))
  )
```

### 진단 및 안정화

그러나 연속형 노출 가중치는 모델링 선택에 매우 민감합니다.
특히 한 가지 문제는 다른 유형의 노출에도 영향을 미칠 수 있는 문제인 극단적인 가중치의 존재입니다.
일부 관찰에 극단적인 가중치가 있는 경우 성향이 *불안정*해져 신뢰 구간이 넓어집니다.
노출의 주변 분포를 사용하여 안정화할 수 있습니다.
성향 점수에 대한 주변 분포를 계산하는 일반적인 방법은 예측 변수가 없는 회귀 모델을 사용하는 것입니다.

::: callout-caution
극단적인 가중치는 추정치를 불안정하게 만들어 신뢰 구간을 넓힙니다.
극단적인 가중치는 제한되지 않은 모든 유형의 가중치(이진 및 기타 유형의 노출에 대한 가중치 포함)에 문제가 될 수 있습니다.
그러나 ATO와 같이 제한된 가중치(0과 1로 제한됨)는 이 문제가 없으며, 이는 많은 이점 중 하나입니다.
:::

```{r}
#| eval: false
# 연속형 노출의 경우
lm(
  exposure ~ 1,
  data = df
) |>
  augment(data = df) |>
  transmute(
    numerator = dnorm(exposure, .fitted, mean(.sigma, na.rm = TRUE))
  )

# 이진 노출의 경우
glm(
  exposure ~ 1,
  data = df,
  family = binomial()
) |>
  augment(type.predict = "response", data = df) |>
  select(numerator = .fitted)
```

그런 다음 역수를 취하는 대신 `numerator / denominator`로 가중치를 계산합니다.
게시된 대기 시간 예제에서 시도해 보겠습니다.
먼저 오전 8시 게시된 대기 시간이 오전 9시 실제 대기 시간에 영향을 미치는지에 대한 질문을 해결하기 위해 데이터를 조작하겠습니다.
기준선 데이터(모든 공변량 및 오전 8시 게시된 대기 시간)를 결과(평균 실제 시간)와 결합합니다.
또한 `wait_minutes_actual_avg`에 대한 누락된 데이터가 많으므로 지금은 관찰되지 않은 값을 삭제합니다.

```{r}
library(tidyverse)
library(touringplans)
eight <- seven_dwarfs_train_2018 |>
  filter(wait_hour == 8) |>
  select(-wait_minutes_actual_avg)

nine <- seven_dwarfs_train_2018 |>
  filter(wait_hour == 9) |>
  select(park_date, wait_minutes_actual_avg)

wait_times <- eight |>
  left_join(nine, by = "park_date") |>
  drop_na(wait_minutes_actual_avg)
```

먼저 분모 모델을 계산해 보겠습니다.
공변량과 함께 `wait_minutes_posted_avg`에 대해 `lm()`을 사용하여 모델을 적합시킨 다음, `wait_minutes_posted_avg`(`.fitted`)의 적합된 예측값을 사용하여 `dnorm()`을 사용하여 밀도를 계산합니다.

```{r}
library(broom)
denominator_model <- lm(
  wait_minutes_posted_avg ~
    park_close + park_extra_magic_morning + park_temperature_high + park_ticket_season,
  data = wait_times
)

denominators <- denominator_model |>
  augment(data = wait_times) |>
  mutate(
    denominator = dnorm(
      wait_minutes_posted_avg,
      .fitted,
      mean(.sigma, na.rm = TRUE)
    )
  ) |>
  select(park_date, denominator, .fitted)
```

`denominator`의 역수 값만 사용하면 여러 개의 극단적인 가중치가 발생합니다.

```{r}
#| label: fig-hist-sd-unstable
#| fig.cap: >
#|   게시된 대기 시간에 대한 역확률 가중치 히스토그램. 연속형 노출에 대한 가중치는 극단적인 값을 갖기 쉬우며, 이는 추정치와 분산을 불안정하게 만들 수 있습니다.
denominators |>
  mutate(wts = 1 / denominator) |>
  ggplot(aes(wts)) +
  geom_histogram(fill = "#E69F00", color = "white", bins = 50) +
  scale_x_log10(name = "가중치")
```

@fig-hist-sd-unstable에서는 100을 넘는 여러 가중치와 10,000을 넘는 가중치 하나를 볼 수 있습니다. 이러한 극단적인 가중치는 특정 지점에 과도한 부담을 주어 추정할 결과를 복잡하게 만듭니다.

이제 안정화된 가중치에 사용할 주변 밀도를 적합시켜 보겠습니다.

```{r}
numerator_model <- lm(
  wait_minutes_posted_avg ~ 1,
  data = wait_times
)

numerators <- numerator_model |>
  augment(data = wait_times) |>
  mutate(
    numerator = dnorm(
      wait_minutes_posted_avg,
      .fitted,
      mean(.sigma, na.rm = TRUE)
    )
  ) |>
  select(park_date, numerator)
```

또한 적합된 값을 날짜별로 원래 데이터셋에 다시 결합한 다음 `numerator / denominator`를 사용하여 안정화된 가중치(`swts`)를 계산해야 합니다.

```{r}
wait_times_wts <- wait_times |>
  left_join(numerators, by = "park_date") |>
  left_join(denominators, by = "park_date") |>
  mutate(swts = numerator / denominator)
```

안정화된 가중치는 훨씬 덜 극단적입니다.
안정화된 가중치는 평균이 1에 가까워야 합니다(이 예에서는 `round(mean(wait_times_wts$swts), digits = 2)`임). 이 경우 유사 모집단(즉, 가중 후 동등한 관찰 수)은 원래 표본 크기와 같습니다.
평균이 1에서 멀리 떨어져 있으면 모델 오지정 또는 양성성 위반 문제가 있을 수 있습니다[@hernan2021].

```{r}
#| label: fig-hist-sd-stable
#| fig.cap: >
#|   게시된 대기 시간에 대한 안정화된 역확률 가중치 히스토그램. 이러한 가중치는 훨씬 더 합리적이며 결과 모델이 더 잘 작동하도록 합니다.
ggplot(wait_times_wts, aes(swts)) +
  geom_histogram(fill = "#E69F00", color = "white", bins = 50) +
  scale_x_log10(name = "가중치")
```

노출(평균 게시 대기 시간)을 표준화된 가중치와 비교하면 여전히 매우 높은 가중치가 하나 있습니다.
이것이 문제일까요, 아니면 유효한 데이터 포인트일까요?

```{r}
#| label: fig-stabilized-wts-scatter
#| fig.cap: >
#|   게시된 대기 시간에 대한 안정화된 역확률 가중치 대 게시된 대기 시간 산점도. 평균에서 더 멀리 떨어진 `wait_minutes_posted_avg` 값을 가진 날은 몇 가지 예외를 제외하고 하향 가중되는 것으로 보입니다. 가장 특이한 가중치는 2018년 6월 23일입니다.
ggplot(wait_times_wts, aes(wait_minutes_posted_avg, swts)) +
  geom_point(size = 3, color = "grey80", alpha = 0.7) +
  geom_point(
    data = function(x) filter(x, swts > 10),
    color = "firebrick",
    size = 3
  ) +
  geom_text(
    data = function(x) filter(x, swts > 10),
    aes(label = park_date),
    size = 5,
    hjust = 0,
    nudge_x = -15.5,
    color = "firebrick"
  ) +
  scale_y_log10() +
  labs(x = "평균 게시 대기 시간", y = "안정화된 가중치")
```

```{r}
wait_times_wts |>
  filter(swts > 10) |>
  select(
    park_date,
    wait_minutes_posted_avg,
    .fitted,
    park_close,
    park_extra_magic_morning,
    park_temperature_high,
    park_ticket_season
  ) |>
  knitr::kable()
```

우리 모델은 관찰된 것보다 훨씬 낮은 게시 대기 시간을 예측했으므로 이 날짜는 상향 가중되었습니다.
게시된 시간이 왜 그렇게 높았는지(실제 시간은 훨씬 낮았음)는 모르지만, 그날 [일곱 난쟁이 광산 열차 보물을 파는 플루토](https://disneyparks.disney.go.com/blog/2018/06/disney-doodle-pluto-sniffs-out-fun-at-seven-dwarfs-mine-train/)의 아티스트 렌더링을 찾았습니다.

### 연속형 노출에 대한 결과 모델 적합시키기

## 범주형 노출

{{< include 00-setup.qmd >}}

```{r}
#| echo: false
# TODO: 첫 번째 판이 완료되면 제거
status("unstarted")
```

## 범주형 노출에 대한 성향 점수 계산하기

```{r}
rnorm(5)
```

### 여러 범주를 사용한 진단

### 결과 모델 다시 적합시키기
